{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [00:16<00:00, 9495.18it/s]\n",
      "100%|██████████| 66292/66292 [00:06<00:00, 10146.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from task1_Sentiment_Analysis.Config import Config\n",
    "from task1_Sentiment_Analysis.data_process import pre_process_data, encode_words, encode_data, to_categorical, \\\n",
    "    pad_features\n",
    "\n",
    "# 数据集\n",
    "train_data = pd.read_csv(Config.train_path, sep='\\t')\n",
    "test_data = pd.read_csv(Config.test_path, sep='\\t')\n",
    "\n",
    "train_data_pp = pre_process_data(train_data)\n",
    "test_data_pp = pre_process_data(test_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:39:31.052627400Z",
     "start_time": "2025-03-02T04:39:07.905671800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n",
      "66291\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_pp))\n",
    "print(len(test_data_pp))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:39:44.736100500Z",
     "start_time": "2025-03-02T04:39:44.730620200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [00:16<00:00, 9362.03it/s]\n",
      "100%|██████████| 66292/66292 [00:06<00:00, 9906.87it/s] \n"
     ]
    }
   ],
   "source": [
    "# 构建词典\n",
    "encode_voc = encode_words(train_data_pp + test_data_pp)\n",
    "train_data_int = encode_data(train_data_pp, encode_voc)\n",
    "test_data_int = encode_data(test_data_pp, encode_voc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:27:47.454994300Z",
     "start_time": "2025-03-02T04:27:23.282859400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66291\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data_int))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:28:25.623248700Z",
     "start_time": "2025-03-02T04:28:25.616731100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_target = to_categorical(train_data['Sentiment'], Config.n_classes)  # 将评分转换成one-hot编码\n",
    "\n",
    "train_reviews_lens = Counter([len(x) for x in train_data_int])\n",
    "\n",
    "# 从训练集中删除长度为0的评论\n",
    "non_zero_idx = [ii for ii, review in enumerate(train_data_int) if len(review) != 0]\n",
    "train_data_int = [train_data_int[ii] for ii in non_zero_idx]\n",
    "y_target = np.array([y_target[ii] for ii in non_zero_idx])\n",
    "\n",
    "train_features = pad_features(train_data_int, max(train_reviews_lens))\n",
    "X_test = pad_features(test_data_int, max(train_reviews_lens))\n",
    "\n",
    "# 分割数据集为训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, y_target, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (123924, 30)\n",
      "X_val (30982, 30)\n",
      "X_test (66291, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_val\",X_val.shape)\n",
    "print(\"X_test\",X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:12:33.486437600Z",
     "start_time": "2025-03-02T04:12:33.479931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 调整训练集和验证集的大小，使其样本数能够被批量大小（Config.batch_size）整除\n",
    "train_size = X_train.shape[0] - X_train.shape[0] % Config.batch_size\n",
    "val_size = X_val.shape[0] - X_val.shape[0] % Config.batch_size\n",
    "X_train = X_train[:train_size]\n",
    "X_val = X_val[:val_size]\n",
    "y_train = y_train[:train_size]\n",
    "y_val = y_val[:val_size]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:18:59.614112500Z",
     "start_time": "2025-03-02T04:18:59.611542100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ids_test = np.array([t['PhraseId'] for ii, t in test_data.iterrows()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:19:16.614413200Z",
     "start_time": "2025-03-02T04:19:14.610974300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (66291, 30)\n",
      "ids_test shape: (66292,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"ids_test shape: {ids_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:22:09.580602200Z",
     "start_time": "2025-03-02T04:22:09.572806100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m train_data \u001B[38;5;241m=\u001B[39m TensorDataset(torch\u001B[38;5;241m.\u001B[39mfrom_numpy(X_train), torch\u001B[38;5;241m.\u001B[39mfrom_numpy(y_train))\n\u001B[0;32m      2\u001B[0m valid_data \u001B[38;5;241m=\u001B[39m TensorDataset(torch\u001B[38;5;241m.\u001B[39mfrom_numpy(X_val), torch\u001B[38;5;241m.\u001B[39mfrom_numpy(y_val))\n\u001B[1;32m----> 3\u001B[0m test_data \u001B[38;5;241m=\u001B[39m \u001B[43mTensorDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mids_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\anaconda3\\envs\\pytorch_sd\\lib\\site-packages\\torch\\utils\\data\\dataset.py:205\u001B[0m, in \u001B[0;36mTensorDataset.__init__\u001B[1;34m(self, *tensors)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mtensors: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 205\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[0;32m    206\u001B[0m         tensors[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m tensor\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m tensors\n\u001B[0;32m    207\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSize mismatch between tensors\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtensors \u001B[38;5;241m=\u001B[39m tensors\n",
      "\u001B[1;31mAssertionError\u001B[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(ids_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T04:20:50.947738800Z",
     "start_time": "2025-03-02T04:20:50.893497900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
